import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import load_model
import warnings
warnings.filterwarnings('ignore')

# Thi·∫øt l·∫≠p font cho ti·∫øng Vi·ªát
plt.rcParams['font.family'] = 'DejaVu Sans'

def preprocess_for_lstm(df):
    """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu gi·ªëng nh∆∞ trong qu√° tr√¨nh training"""
    if "DATE" in df.columns:
        df = df.drop(columns=["DATE"])
    
    data = df.copy()
    
    # Cyclic encoding cho c√°c bi·∫øn th·ªùi gian
    data["HOUR_sin"] = np.sin(2 * np.pi * data["HOUR"] / 24)
    data["HOUR_cos"] = np.cos(2 * np.pi * data["HOUR"] / 24)
    data["DAY_sin"] = np.sin(2 * np.pi * data["DAY"] / 31)
    data["DAY_cos"] = np.cos(2 * np.pi * data["DAY"] / 31)
    data["MONTH_sin"] = np.sin(2 * np.pi * data["MONTH"] / 12)
    data["MONTH_cos"] = np.cos(2 * np.pi * data["MONTH"] / 12)
    data["WEEKDAY_sin"] = np.sin(2 * np.pi * data["WEEKDAY"] / 7)
    data["WEEKDAY_cos"] = np.cos(2 * np.pi * data["WEEKDAY"] / 7)
    data = data.drop(columns=["DAY", "MONTH", "HOUR", "WEEKDAY"])
    
    target_col = "ENERGY"
    y = data[[target_col]].values
    X = data.drop(columns=[target_col]).values
    
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()
    X_scaled = scaler_X.fit_transform(X)
    y_scaled = scaler_y.fit_transform(y)
    
    return X_scaled, y_scaled, scaler_X, scaler_y

def create_sequences(X, y, timesteps=24):
    """T·∫°o sequences cho LSTM"""
    Xs, ys = [], []
    for i in range(len(X) - timesteps):
        Xs.append(X[i:i+timesteps])
        ys.append(y[i+timesteps])
    return np.array(Xs), np.array(ys)

def calculate_metrics(y_true, y_pred):
    """T√≠nh to√°n c√°c metrics ƒë√°nh gi√°"""
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    
    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'R¬≤': r2,
        'MAPE': mape
    }

def plot_comparison(y_true, y_pred_basic, y_pred_woa, title="So s√°nh d·ª± ƒëo√°n"):
    """V·∫Ω ƒë·ªì th·ªã so s√°nh c√°c m√¥ h√¨nh"""
    plt.figure(figsize=(15, 10))
    
    # Subplot 1: So s√°nh t·ªïng th·ªÉ
    plt.subplot(2, 2, 1)
    plt.plot(y_true[:200], label='Th·ª±c t·∫ø', linewidth=2, alpha=0.8)
    plt.plot(y_pred_basic[:200], label='LSTM C∆° b·∫£n', linewidth=1.5, alpha=0.8)
    plt.plot(y_pred_woa[:200], label='LSTM + WOA', linewidth=1.5, alpha=0.8)
    plt.title('So s√°nh d·ª± ƒëo√°n (200 ƒëi·ªÉm ƒë·∫ßu)', fontsize=14, fontweight='bold')
    plt.xlabel('Th·ªùi ƒëi·ªÉm')
    plt.ylabel('NƒÉng l∆∞·ª£ng ti√™u th·ª•')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Subplot 2: Scatter plot - LSTM C∆° b·∫£n
    plt.subplot(2, 2, 2)
    plt.scatter(y_true, y_pred_basic, alpha=0.6, s=20)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
    plt.xlabel('Gi√° tr·ªã th·ª±c t·∫ø')
    plt.ylabel('Gi√° tr·ªã d·ª± ƒëo√°n')
    plt.title('LSTM C∆° b·∫£n - Scatter Plot')
    plt.grid(True, alpha=0.3)
    
    # Subplot 3: Scatter plot - LSTM + WOA
    plt.subplot(2, 2, 3)
    plt.scatter(y_true, y_pred_woa, alpha=0.6, s=20, color='orange')
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
    plt.xlabel('Gi√° tr·ªã th·ª±c t·∫ø')
    plt.ylabel('Gi√° tr·ªã d·ª± ƒëo√°n')
    plt.title('LSTM + WOA - Scatter Plot')
    plt.grid(True, alpha=0.3)
    
    # Subplot 4: Histogram c·ªßa sai s·ªë
    plt.subplot(2, 2, 4)
    errors_basic = y_true.flatten() - y_pred_basic.flatten()
    errors_woa = y_true.flatten() - y_pred_woa.flatten()
    
    plt.hist(errors_basic, bins=50, alpha=0.7, label='LSTM C∆° b·∫£n', density=True)
    plt.hist(errors_woa, bins=50, alpha=0.7, label='LSTM + WOA', density=True)
    plt.xlabel('Sai s·ªë d·ª± ƒëo√°n')
    plt.ylabel('M·∫≠t ƒë·ªô')
    plt.title('Ph√¢n b·ªë sai s·ªë d·ª± ƒëo√°n')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def plot_metrics_comparison(metrics_basic, metrics_woa):
    """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh metrics"""
    metrics_names = list(metrics_basic.keys())
    basic_values = list(metrics_basic.values())
    woa_values = list(metrics_woa.values())
    
    x = np.arange(len(metrics_names))
    width = 0.35
    
    fig, ax = plt.subplots(figsize=(12, 6))
    bars1 = ax.bar(x - width/2, basic_values, width, label='LSTM C∆° b·∫£n', alpha=0.8)
    bars2 = ax.bar(x + width/2, woa_values, width, label='LSTM + WOA', alpha=0.8)
    
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Gi√° tr·ªã')
    ax.set_title('So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(metrics_names)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Th√™m gi√° tr·ªã l√™n c√°c c·ªôt
    for bar in bars1:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.4f}', ha='center', va='bottom', fontsize=9)
    
    for bar in bars2:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.4f}', ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    plt.show()

def print_detailed_evaluation(metrics_basic, metrics_woa):
    """In b√°o c√°o ƒë√°nh gi√° chi ti·∫øt"""
    print("="*80)
    print("                    ƒê√ÅNH GI√Å M√î H√åNH LSTM SAU KHI √ÅP D·ª§NG WOA")
    print("="*80)
    
    print("\nüìä B·∫¢NG SO S√ÅNH METRICS:")
    print("-" * 60)
    print(f"{'Metric':<15} {'LSTM C∆° b·∫£n':<15} {'LSTM + WOA':<15} {'C·∫£i thi·ªán':<15}")
    print("-" * 60)
    
    for metric in metrics_basic.keys():
        basic_val = metrics_basic[metric]
        woa_val = metrics_woa[metric]
        
        if metric in ['MAE', 'MSE', 'RMSE', 'MAPE']:  # C√†ng th·∫•p c√†ng t·ªët
            improvement = ((basic_val - woa_val) / basic_val) * 100
            status = "‚úÖ T·ªët h∆°n" if improvement > 0 else "‚ùå K√©m h∆°n"
        else:  # R¬≤ - c√†ng cao c√†ng t·ªët
            improvement = ((woa_val - basic_val) / basic_val) * 100
            status = "‚úÖ T·ªët h∆°n" if improvement > 0 else "‚ùå K√©m h∆°n"
        
        print(f"{metric:<15} {basic_val:<15.4f} {woa_val:<15.4f} {improvement:>+10.2f}% {status}")
    
    print("\nüéØ PH√ÇN T√çCH HI·ªÜU SU·∫§T:")
    print("-" * 40)
    
    # Ph√¢n t√≠ch t·ª´ng metric
    mae_improvement = ((metrics_basic['MAE'] - metrics_woa['MAE']) / metrics_basic['MAE']) * 100
    rmse_improvement = ((metrics_basic['RMSE'] - metrics_woa['RMSE']) / metrics_basic['RMSE']) * 100
    r2_improvement = ((metrics_woa['R¬≤'] - metrics_basic['R¬≤']) / metrics_basic['R¬≤']) * 100
    
    print(f"‚Ä¢ MAE: {'C·∫£i thi·ªán' if mae_improvement > 0 else 'Gi·∫£m'} {abs(mae_improvement):.2f}%")
    print(f"‚Ä¢ RMSE: {'C·∫£i thi·ªán' if rmse_improvement > 0 else 'Gi·∫£m'} {abs(rmse_improvement):.2f}%")
    print(f"‚Ä¢ R¬≤: {'C·∫£i thi·ªán' if r2_improvement > 0 else 'Gi·∫£m'} {abs(r2_improvement):.2f}%")
    
    # ƒê√°nh gi√° t·ªïng th·ªÉ
    print(f"\nüèÜ K·∫æT LU·∫¨N:")
    print("-" * 20)
    if mae_improvement > 0 and rmse_improvement > 0 and r2_improvement > 0:
        print("‚úÖ Thu·∫≠t to√°n WOA ƒë√£ c·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh LSTM")
        print("‚úÖ M√¥ h√¨nh t·ªëi ∆∞u h√≥a cho k·∫øt qu·∫£ d·ª± ƒëo√°n t·ªët h∆°n")
    elif mae_improvement > 0 or rmse_improvement > 0 or r2_improvement > 0:
        print("‚ö†Ô∏è  Thu·∫≠t to√°n WOA c·∫£i thi·ªán m·ªôt s·ªë metrics nh∆∞ng kh√¥ng to√†n di·ªán")
    else:
        print("‚ùå Thu·∫≠t to√°n WOA kh√¥ng c·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh")
        print("‚ùå C·∫ßn xem x√©t l·∫°i tham s·ªë t·ªëi ∆∞u h√≥a")

def main():
    """H√†m ch√≠nh ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh"""
    print("üîÑ ƒêang t·∫£i d·ªØ li·ªáu v√† chu·∫©n b·ªã ƒë√°nh gi√°...")
    
    # 1. Load v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
    df = pd.read_csv("../data/dataset_clean.csv")
    X_scaled, y_scaled, scaler_X, scaler_y = preprocess_for_lstm(df)
    
    # 2. T·∫°o sequences
    timesteps = 24
    X_seq, y_seq = create_sequences(X_scaled, y_scaled, timesteps)
    
    # 3. Chia d·ªØ li·ªáu test
    total_size = len(X_seq)
    train_size = int(total_size * 0.7)
    val_size = int(total_size * 0.15)
    
    X_test = X_seq[train_size+val_size:]
    y_test = y_seq[train_size+val_size:]
    y_test_orig = scaler_y.inverse_transform(y_test)
    
    print(f"‚úÖ D·ªØ li·ªáu test: {X_test.shape[0]} m·∫´u")
    
    # 4. Load c√°c m√¥ h√¨nh
    import os
    
    # Ki·ªÉm tra c√°c file model c√≥ s·∫µn
    model_files = [f for f in os.listdir('../models/') if f.endswith('.h5')]
    print(f"üìÅ C√°c file model c√≥ s·∫µn: {model_files}")
    
    # T√¨m m√¥ h√¨nh c∆° b·∫£n
    basic_model_path = None
    for model_file in model_files:
        if 'optimized' in model_file.lower() or 'basic' in model_file.lower():
            basic_model_path = model_file
            break
    
    if basic_model_path:
        try:
            # Th·ª≠ load v·ªõi custom_objects ƒë·ªÉ x·ª≠ l√Ω l·ªói version
            model_basic = load_model(f"../models/{basic_model_path}", compile=False)
            print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh LSTM c∆° b·∫£n: {basic_model_path}")
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh c∆° b·∫£n: {e}")
            print("üí° Th·ª≠ load model v·ªõi compile=False...")
            try:
                model_basic = load_model(f"../models/{basic_model_path}", compile=False)
                print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh LSTM c∆° b·∫£n (compile=False): {basic_model_path}")
            except Exception as e2:
                print(f"‚ùå V·∫´n kh√¥ng th·ªÉ load model: {e2}")
                return
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh LSTM c∆° b·∫£n")
        print("üí° H√£y ch·∫°y train_lstm.py tr∆∞·ªõc ƒë·ªÉ t·∫°o m√¥ h√¨nh c∆° b·∫£n")
        return
    
    # T√¨m m√¥ h√¨nh WOA
    woa_model_path = None
    for model_file in model_files:
        if 'woa' in model_file.lower():
            woa_model_path = model_file
            break
    
    if woa_model_path:
        try:
            model_woa = load_model(f"../models/{woa_model_path}", compile=False)
            print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh LSTM + WOA: {woa_model_path}")
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh WOA: {e}")
            print("üí° Th·ª≠ load model v·ªõi compile=False...")
            try:
                model_woa = load_model(f"../models/{woa_model_path}", compile=False)
                print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh LSTM + WOA (compile=False): {woa_model_path}")
            except Exception as e2:
                print(f"‚ùå V·∫´n kh√¥ng th·ªÉ load model WOA: {e2}")
                return
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh LSTM + WOA")
        print("üí° H√£y ch·∫°y lstm_woa_optimize.py tr∆∞·ªõc ƒë·ªÉ t·∫°o m√¥ h√¨nh WOA")
        return
    
    # 5. D·ª± ƒëo√°n
    print("üîÑ ƒêang th·ª±c hi·ªán d·ª± ƒëo√°n...")
    y_pred_basic_scaled = model_basic.predict(X_test)
    y_pred_woa_scaled = model_woa.predict(X_test)
    
    y_pred_basic = scaler_y.inverse_transform(y_pred_basic_scaled)
    y_pred_woa = scaler_y.inverse_transform(y_pred_woa_scaled)
    
    # 6. T√≠nh metrics
    print("üîÑ ƒêang t√≠nh to√°n metrics...")
    metrics_basic = calculate_metrics(y_test_orig, y_pred_basic)
    metrics_woa = calculate_metrics(y_test_orig, y_pred_woa)
    
    # 7. In b√°o c√°o chi ti·∫øt
    print_detailed_evaluation(metrics_basic, metrics_woa)
    
    # 8. V·∫Ω ƒë·ªì th·ªã so s√°nh
    print("\nüìà ƒêang t·∫°o bi·ªÉu ƒë·ªì so s√°nh...")
    plot_comparison(y_test_orig, y_pred_basic, y_pred_woa)
    plot_metrics_comparison(metrics_basic, metrics_woa)
    
    # 9. L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√°
    evaluation_results = pd.DataFrame({
        'Metric': list(metrics_basic.keys()),
        'LSTM_Basic': list(metrics_basic.values()),
        'LSTM_WOA': list(metrics_woa.values())
    })
    
    evaluation_results['Improvement_%'] = [
        ((metrics_basic[metric] - metrics_woa[metric]) / metrics_basic[metric]) * 100 
        if metric in ['MAE', 'MSE', 'RMSE', 'MAPE'] 
        else ((metrics_woa[metric] - metrics_basic[metric]) / metrics_basic[metric]) * 100
        for metric in metrics_basic.keys()
    ]
    
    evaluation_results.to_csv("../data/evaluation_results_woa.csv", index=False)
    print("\nüíæ K·∫øt qu·∫£ ƒë√°nh gi√° ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_results_woa.csv'")
    
    print("\nüéâ Ho√†n th√†nh ƒë√°nh gi√° m√¥ h√¨nh!")

if __name__ == "__main__":
    main()
